{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/PC/Desktop/mitacs/Projet/ansible/playbooks/Model/model_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>type</th>\n",
       "      <th>LOC_playbook</th>\n",
       "      <th>num_plays</th>\n",
       "      <th>num_tasks_playbook</th>\n",
       "      <th>avg_task_playbook</th>\n",
       "      <th>Num_Imports</th>\n",
       "      <th>Num_Roles</th>\n",
       "      <th>similarity</th>\n",
       "      <th>LOC_play</th>\n",
       "      <th>num_tasks_play</th>\n",
       "      <th>avg_task_play</th>\n",
       "      <th>special_chars_play</th>\n",
       "      <th>LOC_task</th>\n",
       "      <th>task_name_len</th>\n",
       "      <th>special_chars_task</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\PC\\Desktop\\mitacs\\Projet\\ansible\\play...</td>\n",
       "      <td>playbook</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.445803</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Incohesive Playbook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\PC\\Desktop\\mitacs\\Projet\\ansible\\play...</td>\n",
       "      <td>playbook</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complex playbook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\PC\\Desktop\\mitacs\\Projet\\ansible\\play...</td>\n",
       "      <td>playbook</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>high playbook coupling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\PC\\Desktop\\mitacs\\Projet\\ansible\\play...</td>\n",
       "      <td>playbook</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Large Playbook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run docker osf adminserver container</td>\n",
       "      <td>task</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Large Task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>C:\\Users\\PC\\Desktop\\mitacs\\Projet\\ansible\\play...</td>\n",
       "      <td>playbook</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Inconsistent Naming Convention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>service-guest-image | upload-image | find imag...</td>\n",
       "      <td>task</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Large Task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>service-guest-image | upload-image | find imag...</td>\n",
       "      <td>task</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>Long Task Name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>service-guest-image | upload-image | Upload ne...</td>\n",
       "      <td>task</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Large Task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Ensure the VM disk volumes exist</td>\n",
       "      <td>task</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Large Task</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  item      type  \\\n",
       "0    C:\\Users\\PC\\Desktop\\mitacs\\Projet\\ansible\\play...  playbook   \n",
       "1    C:\\Users\\PC\\Desktop\\mitacs\\Projet\\ansible\\play...  playbook   \n",
       "2    C:\\Users\\PC\\Desktop\\mitacs\\Projet\\ansible\\play...  playbook   \n",
       "3    C:\\Users\\PC\\Desktop\\mitacs\\Projet\\ansible\\play...  playbook   \n",
       "4                 Run docker osf adminserver container      task   \n",
       "..                                                 ...       ...   \n",
       "238  C:\\Users\\PC\\Desktop\\mitacs\\Projet\\ansible\\play...  playbook   \n",
       "239  service-guest-image | upload-image | find imag...      task   \n",
       "240  service-guest-image | upload-image | find imag...      task   \n",
       "241  service-guest-image | upload-image | Upload ne...      task   \n",
       "242                   Ensure the VM disk volumes exist      task   \n",
       "\n",
       "     LOC_playbook  num_plays  num_tasks_playbook  avg_task_playbook  \\\n",
       "0               0          0                   0                  0   \n",
       "1              43          1                   0                  0   \n",
       "2               0          0                   0                  0   \n",
       "3              43          1                   0                  0   \n",
       "4               0          0                   0                  0   \n",
       "..            ...        ...                 ...                ...   \n",
       "238             0          0                   0                  0   \n",
       "239             0          0                   0                  0   \n",
       "240             0          0                   0                  0   \n",
       "241             0          0                   0                  0   \n",
       "242             0          0                   0                  0   \n",
       "\n",
       "     Num_Imports  Num_Roles  similarity  LOC_play  num_tasks_play  \\\n",
       "0              0          0    0.445803         0               0   \n",
       "1              0         24    0.000000         0               0   \n",
       "2              0         24    0.000000         0               0   \n",
       "3              0          0    0.000000         0               0   \n",
       "4              0          0    0.000000         0               0   \n",
       "..           ...        ...         ...       ...             ...   \n",
       "238            0          0    0.000000         0               0   \n",
       "239            0          0    0.000000         0               0   \n",
       "240            0          0    0.000000         0               0   \n",
       "241            0          0    0.000000         0               0   \n",
       "242            0          0    0.000000         0               0   \n",
       "\n",
       "     avg_task_play  special_chars_play  LOC_task  task_name_len  \\\n",
       "0              0.0                   0         0              0   \n",
       "1              0.0                   0         0              0   \n",
       "2              0.0                   0         0              0   \n",
       "3              0.0                   0         0              0   \n",
       "4              0.0                   0        20              0   \n",
       "..             ...                 ...       ...            ...   \n",
       "238            0.0                   0         0              0   \n",
       "239            0.0                   0        19              0   \n",
       "240            0.0                   0         0             82   \n",
       "241            0.0                   0        20              0   \n",
       "242            0.0                   0        17              0   \n",
       "\n",
       "     special_chars_task                            class  \n",
       "0                     0              Incohesive Playbook  \n",
       "1                     0                 complex playbook  \n",
       "2                     0           high playbook coupling  \n",
       "3                     0                   Large Playbook  \n",
       "4                     0                       Large Task  \n",
       "..                  ...                              ...  \n",
       "238                   0  Inconsistent Naming Convention   \n",
       "239                   0                       Large Task  \n",
       "240                   0                   Long Task Name  \n",
       "241                   0                       Large Task  \n",
       "242                   0                       Large Task  \n",
       "\n",
       "[243 rows x 17 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une correspondance entre chaque \"smell code\" unique et un label distinct\n",
    "smells = df['class'].unique()\n",
    "smell_to_label = {smell: f\"cs{i+1}\" for i, smell in enumerate(smells)}\n",
    "df['smell_label'] = df['class'].map(smell_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "df['smell_labels'] = df['smell_label'].values.tolist()\n",
    "df_encoded = mlb.fit_transform(df['smell_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['LOC_playbook', 'num_plays', 'num_tasks_playbook', 'avg_task_playbook', 'Num_Imports' , 'Num_Roles' , 'similarity' , 'LOC_play' , 'num_tasks_play' , 'avg_task_play', 'special_chars_play', 'LOC_task', 'task_name_len', 'special_chars_task']]\n",
    "y = df_encoded\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df = pd.DataFrame(y_train, columns=mlb.classes_)\n",
    "colonnes_une_classe = [col for col in y_train_df.columns if y_train_df[col].nunique() == 1]\n",
    "y_train_df = y_train_df.drop(columns=colonnes_une_classe)\n",
    "y_train = y_train_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df = pd.DataFrame(y_test, columns=mlb.classes_)\n",
    "y_test_df = y_test_df.drop(columns=colonnes_une_classe)\n",
    "y_test = y_test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOC_playbook          0\n",
      "num_plays             0\n",
      "num_tasks_playbook    0\n",
      "avg_task_playbook     0\n",
      "Num_Imports           0\n",
      "Num_Roles             0\n",
      "similarity            0\n",
      "LOC_play              0\n",
      "num_tasks_play        0\n",
      "avg_task_play         0\n",
      "special_chars_play    0\n",
      "LOC_task              0\n",
      "task_name_len         0\n",
      "special_chars_task    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Pour identifier les valeurs NaN\n",
    "print(X_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(max_iter=10000))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiOutputClassifier(LogisticRegression(max_iter=10000))\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOC_playbook          0\n",
      "num_plays             0\n",
      "num_tasks_playbook    0\n",
      "avg_task_playbook     0\n",
      "Num_Imports           0\n",
      "Num_Roles             0\n",
      "similarity            0\n",
      "LOC_play              0\n",
      "num_tasks_play        0\n",
      "avg_task_play         0\n",
      "special_chars_play    0\n",
      "LOC_task              0\n",
      "task_name_len         0\n",
      "special_chars_task    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Pour identifier les valeurs NaN\n",
    "print(X_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8775510204081632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86         3\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.88      0.70      0.78        10\n",
      "           4       1.00      1.00      1.00        24\n",
      "           5       1.00      1.00      1.00         6\n",
      "           6       1.00      0.67      0.80         3\n",
      "           7       1.00      1.00      1.00         1\n",
      "           8       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.91      0.88      0.90        49\n",
      "   macro avg       0.62      0.60      0.60        49\n",
      "weighted avg       0.92      0.88      0.89        49\n",
      " samples avg       0.88      0.88      0.88        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label_col, coef in zip(y_train_df.columns, model.estimators_):\n",
    "    print(f\"Pour le code smell '{label_col}':\")\n",
    "    for feature_name, coefficient in zip(X.columns, coef.coef_[0]):\n",
    "        print(f\"{feature_name}: {coefficient}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resultats.txt\", \"w\") as f:\n",
    "    for label_col, coef in zip(y_train_df.columns, model.estimators_):\n",
    "        f.write(f\"Pour le code smell '{label_col}':\\n\")\n",
    "        for feature_name, coefficient in zip(X.columns, coef.coef_[0]):\n",
    "            f.write(f\"{feature_name}: {coefficient}\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustez la correspondance pour tenir compte des étiquettes '0', '1', etc.\n",
    "# au lieu de 'cs1', 'cs2', etc.\n",
    "adjusted_label_to_smell = {str(i): v for i, v in enumerate(smell_to_label.values())}\n",
    "\n",
    "with open(\"resultats.txt\", \"w\") as f:\n",
    "    for label_col, coef in zip(y_train_df.columns, model.estimators_):\n",
    "        # Obtenez le nom du code smell à partir du label ajusté\n",
    "        code_smell_name = adjusted_label_to_smell[label_col]\n",
    "        f.write(f\"Pour le code smell '{code_smell_name}':\\n\")\n",
    "        for feature_name, coefficient in zip(X.columns, coef.coef_[0]):\n",
    "            f.write(f\"{feature_name}: {coefficient}\\n\")\n",
    "        f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le DataFrame dans un fichier CSV\n",
    "df.to_csv('C:/Users/PC/Desktop/mitacs/Projet/ansible/playbooks/Model/df_labled_smell_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
